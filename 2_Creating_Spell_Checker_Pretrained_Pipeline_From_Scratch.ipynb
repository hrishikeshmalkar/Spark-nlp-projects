{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-Creating_Spell_Checker_Pretrained_Pipeline_From_Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN1rwy4mvaG68SKRNx48bQF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrishikeshmalkar/Spark-nlp-projects/blob/main/2_Creating_Spell_Checker_Pretrained_Pipeline_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CAx6bv4e977"
      },
      "source": [
        "# Spell-Checker DL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGWtmBQOe4_N"
      },
      "source": [
        "#### Creating a Pretrained Pipeline From Scratch\n",
        "Let's start with building a pipeline; a *spell correction pipeline*. We will use a pretrained model from our library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITJ2V9bdfUr1"
      },
      "source": [
        "# Setting Spark Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWrxSEH0fU9u",
        "outputId": "fa689080-50b1-4dad-8df7-e2e8804f807d"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
        "!bash colab_setup.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-12 14:35:46--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1593 (1.6K) [text/plain]\n",
            "Saving to: ‘colab_setup.sh.1’\n",
            "\n",
            "colab_setup.sh.1    100%[===================>]   1.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-12 14:35:46 (14.9 MB/s) - ‘colab_setup.sh.1’ saved [1593/1593]\n",
            "\n",
            "setup Colab for PySpark 3.1.1 and Spark NLP 3.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDGshU3jQqBc"
      },
      "source": [
        "# Importing required libraries\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVfvd8u0fIgx"
      },
      "source": [
        "from IPython.utils.text import columnize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LRu91JUgdh3"
      },
      "source": [
        "#### Starting Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWeUyVRPgdvr"
      },
      "source": [
        "spark = sparknlp.start()\n",
        "\n",
        "# params =>> gpu=False, spark23=False (start with spark 2.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUCPDEfsg1HG",
        "outputId": "b3ef2e7f-447a-4d74-ee9f-f1b355d8189b"
      },
      "source": [
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version 3.0.1\n",
            "Apache Spark version: 3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht2qoe2Ig0Lr"
      },
      "source": [
        "#### Defining Stages with SpellChecker_Pretrained_Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIilQpAUfbjQ",
        "outputId": "a1b53108-e47a-4389-9321-13c86e0ad13e"
      },
      "source": [
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"token\")\\\n",
        "    \n",
        "spellModel = ContextSpellCheckerModel\\\n",
        "    .pretrained('spellcheck_dl')\\\n",
        "    .setInputCols(\"token\")\\\n",
        "    .setOutputCol(\"checked\")\\\n",
        "    .setErrorThreshold(4.0)\\\n",
        "    .setTradeoff(6.0)\n",
        "\n",
        "finisher = Finisher()\\\n",
        "    .setInputCols(\"checked\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spellcheck_dl download started this may take some time.\n",
            "Approximate size to download 111.4 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aopbhLvQgKVx"
      },
      "source": [
        "#### Creating a Normal Pipelinem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuOODz50fxz2"
      },
      "source": [
        "pipeline = Pipeline(\n",
        "    stages = [\n",
        "    document,\n",
        "    tokenizer,\n",
        "    spellModel,\n",
        "    finisher\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsNzqFUYhOig"
      },
      "source": [
        "#### Creating Empty Dataframe and using in pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfMdRcwIf1eJ"
      },
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uxmwNW0f4H6"
      },
      "source": [
        "spell_pipeline = pipeline.fit(empty_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7Kd2cajhXkL",
        "outputId": "fdf9776f-5f1a-4a92-f0ad-7bf58c9ff86a"
      },
      "source": [
        "spell_pipeline.stages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DocumentAssembler_8cedde72ea90,\n",
              " REGEX_TOKENIZER_c4c9f6809e47,\n",
              " SPELL_b22681bc00ec,\n",
              " Finisher_ef646736b663]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK2tQ2Ebhlnt"
      },
      "source": [
        "#### Saving our Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZlIcmeIhcs6"
      },
      "source": [
        "spell_pipeline.save('SavedSpellChecker')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSIraXH_hxhu"
      },
      "source": [
        "#### Cross-Checking wheather our model was saved or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olDcpHUshvJh",
        "outputId": "f79ef4f3-91a6-4bb2-be2c-fdafa6f5f9e8"
      },
      "source": [
        "!ls -lt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 438252\n",
            "drwxr-xr-x  4 root root      4096 Apr 12 14:40 SavedSpellChecker\n",
            "-rw-r--r--  1 root root      1593 Apr 12 14:35 colab_setup.sh.1\n",
            "-rw-r--r--  1 root root      1593 Apr 12 14:30 colab_setup.sh\n",
            "drwxr-xr-x  1 root root      4096 Apr  7 13:36 sample_data\n",
            "-rw-r--r--  1 root root 224374704 Feb 22 02:45 spark-3.1.1-bin-hadoop2.7.tgz\n",
            "-rw-r--r--  1 root root 224374704 Feb 22 02:45 spark-3.1.1-bin-hadoop2.7.tgz.1\n",
            "drwxr-xr-x 13 1000 1000      4096 Feb 22 02:44 spark-3.1.1-bin-hadoop2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccAlOToxh32r"
      },
      "source": [
        "#### Loading our saved spell-pipeline-model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U5uFBAbiSvX"
      },
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "pipeline_local = PretrainedPipeline.from_disk('SavedSpellChecker')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhNLjF30ia8u"
      },
      "source": [
        "#### Model testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd8M87Sgh0z1"
      },
      "source": [
        "testDoc = '''\n",
        "During the rainy seacon we have th best ueather and \"I have a black ueather jacket, so nice.\"\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB3wru5wif_e"
      },
      "source": [
        "result = pipeline_local.annotate(testDoc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-DYPOFUihsF",
        "outputId": "fe8fe2e4-a2e9-425a-f88f-0de0c8bd14fc"
      },
      "source": [
        "result.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['checked'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drCT11Eyin-q",
        "outputId": "62ab2958-fc45-419e-c0a1-b8aa1c3c4376"
      },
      "source": [
        "result['checked']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['During',\n",
              " 'the',\n",
              " 'rainy',\n",
              " 'season',\n",
              " 'we',\n",
              " 'have',\n",
              " 'the',\n",
              " 'best',\n",
              " 'weather',\n",
              " 'and',\n",
              " '\"',\n",
              " 'I',\n",
              " 'have',\n",
              " 'a',\n",
              " 'black',\n",
              " 'leather',\n",
              " 'jacket',\n",
              " ',',\n",
              " 'so',\n",
              " 'nice',\n",
              " '.\"']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9g98wbdirP1"
      },
      "source": [
        "corrected_text = ''\n",
        "for i in result['checked']:\n",
        "  corrected_text = corrected_text +' '+ i\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "USzBKntFi9Ku",
        "outputId": "176f3835-510d-41cf-d267-c7b93d1f9fcf"
      },
      "source": [
        "corrected_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' During the rainy season we have the best weather and \" I have a black leather jacket , so nice .\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "188HznXKi-P5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}